{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Rock AI is a \ud83d\ude80 platform designed specifically for programmers, offering the ability to effortlessly interact with machine learning models for inference. It's a game-changer in empowering developers to unlock the full potential of their projects! \ud83e\udd16\ud83d\udcbb</p>"},{"location":"#collections","title":"Collections","text":"<p>Checkout our collections, to find out models you need to boost your productivity</p> <p>\ud83d\udd27 Utilities: Toolbelt-type models for captioning videos, combining images into videos, extracting frames from videos, extracting audio from video, etc.</p> <p>\ud83c\udf10 3D models: Models that generate 3D objects, scenes, radiance fields, textures, and multi-views.</p> <p>\ud83d\udc41\ufe0f Vision models: Multimodal large language models with vision capabilities like object detection and optical character recognition (OCR).</p> <p>\ud83d\uddbc\ufe0f T2I-Adapter: T2I-Adapter models to modify images.</p> <p>\ud83d\udcda Language models with support for grammars and jsonschema: Language models that support grammar-based decoding as well as JSON schema constraints.</p> <p>\ud83c\udfa8 SDXL fine-tunes: Some of our favorite SDXL fine-tunes.</p> <p>\ud83c\udf0a Streaming language models: Language models that support streaming responses. See here.</p> <p>\ud83d\udd8c\ufe0f Image editing: Tools for manipulating images.</p> <p>\ud83d\udd0d Embedding models: Models that generate embeddings from inputs.</p> <p>\ud83c\udf93 Trainable language models: Language models that you can fine-tune using Replicate's training API.</p> <p>\ud83d\udcdd Language models: Models that can understand and generate text.</p> <p>\u2699\ufe0f ControlNet: Control diffusion models.</p> <p>\ud83c\udfb5 Audio generation: Models to generate and modify audio.</p> <p>\ud83c\udf05 Diffusion models: Image and video generation models trained with diffusion processes.</p> <p>\ud83d\udcf9 Videos: Models that create and edit videos.</p> <p>\ud83d\udcf7 Image to text: Models that generate text prompts and captions from images.</p> <p>\ud83d\udd0d Image upscaling: Upscaling models that create high-quality images from low-quality images.</p> <p>\ud83c\udfa8 Style transfer: Models that take a content image and a style reference to produce a new image.</p> <p>\ud83d\udc84 ML makeovers: Models that let you change facial features.</p> <p>\ud83d\uddbc\ufe0f Image restoration: Models that improve or restore images by deblurring, colorization, and removing noise.</p> <p>\ud83d\udcdd Text to image: Models that generate images from text prompts.</p>"},{"location":"get_start/","title":"Getting Start","text":"<p>You can do inference with our HTTP API</p>"},{"location":"get_start/#http-api","title":"HTTP API","text":""},{"location":"get_start/#authentication","title":"Authentication","text":"<p>All API requests must be authenticated with a token. Include this header with all requests:</p> <pre><code>Authorization: Bearer &lt;paste-your-api-key-here&gt;\n</code></pre>"},{"location":"get_start/#create-a-prediction","title":"Create a prediction","text":"<pre><code>import requests\nimport json\n\nurl = \"https://inf-test-dev-mhvxow5uwq-de.a.run.app/v1/predictions\"\n\npayload = json.dumps({\n    \"version\": \"5821a338d00033abaaba89080a17eb8783d9a17ed710a6b4246a18e0900ccad4\",\n    \"input\": {\n        \"image\": \"https://replicate.delivery/pbxt/KAaJWyluKBrWzbe5EhQArYZcVXdpOvcLyF81menWifyusgCe/1.jpeg\",\n        \"prompt\": \"Several statues made of porcelain chunks and gold mendings, the face of the statues have lips and eyes, the eyes are blinking, the lips are opening like the statues are talking, the head of the statues are turning towards the camera\",\n        \"max_frames\": 16,\n        \"guidance_scale\": 9,\n        \"num_inference_steps\": 50\n    }\n})\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;paste-your-token-here&gt;'\n}\n\nresponse = requests.request(\"POST\", url, headers=headers, data=payload)\n\nprint(response.text)\n\n</code></pre>"},{"location":"get_start/#get-a-prediction","title":"Get a prediction","text":"<pre><code>import requests\n\nurl = \"https://inf-test-dev-mhvxow5uwq-de.a.run.app/v1/predictions/ujebapbbulzpx25442efjv4qba\"\n\npayload = {}\nheaders = {\n    'Authorization': 'Bearer &lt;paste-your-token-here&gt;'\n}\n\nresponse = requests.request(\"GET\", url, headers=headers, data=payload)\n\nprint(response.text)\n\n</code></pre>"},{"location":"get_start/#cancel-a-prediction","title":"Cancel a prediction","text":"<pre><code>import requests\n\nurl = \"https://inf-test-dev-mhvxow5uwq-de.a.run.app/v1/predictions/eoyokbzbm3yfdhpspr5xak24ye/cancel\"\n\npayload = {}\nheaders = {}\n\nresponse = requests.request(\"POST\", url, headers=headers, data=payload)\n\nprint(response.text)\n\n</code></pre>"},{"location":"get_start/#run-a-model","title":"Run a model","text":"<pre><code>import requests\nimport json\n\nurl = \"https://inf-test-dev-mhvxow5uwq-de.a.run.app/v1/run\"\n\npayload = json.dumps({\n    \"model\": \"mistralai/mistral-7b-instruct-v0.1:5fe0a3d7ac2852264a25279d1dfb798acbc4d49711d126646594e212cb821749\",\n    \"input\": {\n        \"top_k\": 50,\n        \"top_p\": 0.9,\n        \"prompt\": \"Can you write me a poem about steamed hams?\",\n        \"temperature\": 0.7,\n        \"max_new_tokens\": 500,\n        \"min_new_tokens\": -1,\n        \"prompt_template\": \"{prompt}\",\n        \"repetition_penalty\": 1.15\n    }\n})\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;paste-your-token-here&gt;'\n}\n\nresponse = requests.request(\"POST\", url, headers=headers, data=payload)\n\nprint(response.text)\n\n</code></pre>"},{"location":"get_start/#run-a-model-with-server-side-event","title":"Run a model with server side event","text":"<pre><code>import requests\nimport json\n\nurl = \"https://inf-test-dev-mhvxow5uwq-de.a.run.app/v1/run_sse\"\n\npayload = json.dumps({\n    \"model\": \"meta/llama-2-7b-chat:f1d50bb24186c52daae319ca8366e53debdaa9e0ae7ff976e918df752732ccc4\",\n    \"input\": {\n        \"top_p\": 1,\n        \"prompt\": \"Plan a day of sightseeing for me in San Francisco. \",\n        \"temperature\": 0.75,\n        \"system_prompt\": \"You are an old-timey gold prospector who came to San Francisco for the gold rush and then was teleported to the present day. Despite being from 1849, you have great knowledge of present-day San Francisco and its attractions. You are helpful, polite, and prone to rambling. \",\n        \"max_new_tokens\": 800,\n        \"repetition_penalty\": 1\n    }\n})\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer &lt;paste-your-token-here&gt;'\n}\n\nresponse = requests.request(\"POST\", url, headers=headers, data=payload)\n\nprint(response.text)\n\n</code></pre>"},{"location":"public_model/","title":"Public Model","text":"<p>We offer tons of model to choose from! Below are an example of model, be sure to check our website for more!</p>"},{"location":"public_model/#models","title":"Models","text":""},{"location":"public_model/#cjwbwunidiffuser","title":"cjwbw/unidiffuser","text":""},{"location":"public_model/#one-transformer-fits-all-distributions-in-multi-modal-diffusion-at-scale","title":"One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale","text":""},{"location":"public_model/#_1","title":"Public Model","text":""},{"location":"public_model/#joehoovermplug-owl","title":"joehoover/mplug-owl","text":""},{"location":"public_model/#an-instruction-tuned-multimodal-large-language-model-that-generates-text-based-on-user-provided-prompts-and-images","title":"An instruction-tuned multimodal large language model that generates text based on user-provided prompts and images","text":""},{"location":"public_model/#_2","title":"Public Model","text":""},{"location":"public_model/#daanelsonminigpt-4","title":"daanelson/minigpt-4","text":""},{"location":"public_model/#a-model-which-generates-text-in-response-to-an-input-image-and-prompt","title":"A model which generates text in response to an input image and prompt.","text":""},{"location":"public_model/#_3","title":"Public Model","text":""},{"location":"public_model/#cjwbwunival","title":"cjwbw/unival","text":""},{"location":"public_model/#unified-model-for-image-video-audio-and-language-tasks","title":"Unified Model for Image, Video, Audio and Language Tasks","text":""},{"location":"public_model/#_4","title":"Public Model","text":""},{"location":"public_model/#lucatacoqwen-vl-chat","title":"lucataco/qwen-vl-chat","text":""},{"location":"public_model/#a-multimodal-llm-based-ai-assistant-which-is-trained-with-alignment-techniques-qwen-vl-chat-supports-more-flexible-interaction-such-as-multi-round-question-answering-and-creative-capabilities","title":"A multimodal LLM-based AI assistant, which is trained with alignment techniques. Qwen-VL-Chat supports more flexible interaction, such as multi-round question answering, and creative capabilities.","text":""},{"location":"public_model/#_5","title":"Public Model","text":""},{"location":"public_model/#cjwbwidefics","title":"cjwbw/idefics","text":""},{"location":"public_model/#open-access-reproduction-of-large-visual-language-model-flamingo","title":"Open-access reproduction of large visual language model Flamingo","text":""},{"location":"public_model/#_6","title":"Public Model","text":""},{"location":"public_model/#alaradiriknougat","title":"alaradirik/nougat","text":""},{"location":"public_model/#nougat-neural-optical-understanding-for-academic-documents","title":"Nougat: Neural Optical Understanding for Academic Documents","text":""},{"location":"public_model/#_7","title":"Public Model","text":""},{"location":"public_model/#cjwbwinternlm-xcomposer","title":"cjwbw/internlm-xcomposer","text":""},{"location":"public_model/#advanced-text-image-comprehension-and-composition-based-on-internlm","title":"Advanced text-image comprehension and composition based on InternLM","text":""},{"location":"public_model/#_8","title":"Public Model","text":""},{"location":"public_model/#yorickvpllava-13b","title":"yorickvp/llava-13b","text":""},{"location":"public_model/#visual-instruction-tuning-towards-large-language-and-vision-models-with-gpt-4-level-capabilities","title":"Visual instruction tuning towards large language and vision models with GPT-4 level capabilities","text":""},{"location":"public_model/#_9","title":"Public Model","text":""},{"location":"public_model/#alaradirikowlvit-base-patch32","title":"alaradirik/owlvit-base-patch32","text":""},{"location":"public_model/#zero-shot-open-vocabulary-object-detection","title":"Zero-shot / open vocabulary object detection","text":""},{"location":"public_model/#_10","title":"Public Model","text":""},{"location":"public_model/#adirikkosmos-g","title":"adirik/kosmos-g","text":""},{"location":"public_model/#kosmos-g-generating-images-in-context-with-multimodal-large-language-models","title":"Kosmos-G: Generating Images in Context with Multimodal Large Language Models","text":""},{"location":"public_model/#_11","title":"Public Model","text":""},{"location":"public_model/#adirikmasactrl-sdxl","title":"adirik/masactrl-sdxl","text":""},{"location":"public_model/#editable-image-generation-with-masactrl-sdxl","title":"Editable image generation with MasaCtrl-SDXL","text":""},{"location":"public_model/#_12","title":"Public Model","text":""},{"location":"blog/","title":"Blog","text":""}]}